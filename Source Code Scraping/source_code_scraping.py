# -*- coding: utf-8 -*-
"""Source Code Scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19BSBdv6uqKpZuV9SzSXM1iTYftFw0V5u

202010370311391 - Ungga Putra Mahendra
"""

!pip install selenium

pip install requests

pip install tqdm

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# 
# # Add debian buster
# cat > /etc/apt/sources.list.d/debian.list <<'EOF'
# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main
# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main
# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main
# EOF
# 
# # Add keys
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A
# 
# apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg
# apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg
# apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg
# 
# # Prefer debian repo for chromium* packages only
# # Note the double-blank lines between entries
# cat > /etc/apt/preferences.d/chromium.pref << 'EOF'
# Package: *
# Pin: release a=eoan
# Pin-Priority: 500
# 
# 
# Package: *
# Pin: origin "deb.debian.org"
# Pin-Priority: 300
# 
# 
# Package: chromium*
# Pin: origin "deb.debian.org"
# Pin-Priority: 700
# EOF
#

!apt-get update
!apt-get install chromium chromium-driver

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.common.exceptions import StaleElementReferenceException
from tqdm import tqdm
import os
import sys
from pathlib import Path
import requests
import threading

# Setup Chrome options
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--headless')
chrome_options.add_argument('--disable-gpu')

# Buat instance WebDriver
driver = webdriver.Chrome(options=chrome_options)

main_url = 'https://putusan3.mahkamahagung.go.id/direktori/index/pengadilan/pn-madiun/kategori/narkotika-dan-psikotropika-1/tahunjenis/upload/tahun/2022'
# Variable pages digunakan untuk menyimpan semua page yang ditemukan pada URL utama
pages = set()

def main_func(url):
  temp = set()
  driver.get(url)
  all_links = driver.find_elements(By.CLASS_NAME, 'entry-c')

  # Loop melalui setiap elemen yang ditemukan
  for link in all_links:
    strong_elements = link.find_elements(By.TAG_NAME, 'strong')

    for strong_element in strong_elements:
      a_elements = strong_element.find_elements(By.TAG_NAME, 'a')

      for a_element in a_elements:
        page_url = a_element.get_attribute('href')

        if page_url:
          temp.add(page_url)

  return temp

pages = pages | main_func(main_url)

for i in range(2, 5):
  temp_url = f'{main_url}/page/{i}.html'
  pages = pages | main_func(temp_url)

# Cetak semua URL yang telah ditemukan
for page in pages:
  print(page)

def getpdflink(list_urls):
  hrefs = []
  # Loop melalui setiap link yang ada pada 'listed_pages'
  for link in list_urls:
    driver.get(link)

    # Mencari elemen <div> dengan ID 'collapseThree'
    collapseThree_element = driver.find_element(By.ID, 'collapseThree')

    # Mencari elemen <ul> dalam elemen <div>
    ul_element = collapseThree_element.find_element(By.TAG_NAME, 'ul')

    # Mencari semua elemen <li> dalam elemen <ul>
    li_elements = ul_element.find_elements(By.TAG_NAME, 'li')

    for li_element in li_elements:
        a_elements = li_element.find_elements(By.TAG_NAME, 'a')

        for a_element in a_elements:
            text = a_element.text
            # Menambahkan kondisi untuk memeriksa apakah teks diakhiri dengan ".pdf"
            if text.endswith('.pdf'):
                href = a_element.get_attribute('href')
                hrefs.append(href)

  return hrefs

# Menampilkan semua link download pdf yang didapat
all_link = getpdflink(list(pages))
for href in all_link:
  print(href)

from google.colab import drive
drive.mount('/content/gdrive')

# Download semua file dan disimpan ke Google Drive
for fileurl in all_link:
  filename = os.path.basename(fileurl)
  r = requests.get(fileurl, stream = True)

  with open(f'/content/gdrive/My Drive/Colab Notebooks/Temu Kembali Informasi/Dataset/{filename}.pdf', 'wb') as file:
    for block in r.iter_content(chunk_size = 1024):
      if block:
        file.write(block)